{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Wq6_2Isla8ykFPy6Oo9vOYucoi0WFdyD",
      "authorship_tag": "ABX9TyNCZkggxA0oWdOd4XgIsxue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marconi-Lab/katunda_project/blob/main/combined_katunda_classification_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HroETOl9e7sh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get dataset\n",
        "\n",
        "!cp '/content/drive/MyDrive/katunda_classification.zip' 'katunda_dataset.zip'\n",
        "\n",
        "local_zip = 'katunda_dataset.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('.')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "7fUU2YkFrsa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = '/content/katunda_classification'\n",
        "\n",
        "source_path_fruit_brownspot = os.path.join(source_path, 'Fruit_Brownspot')\n",
        "source_path_fruit_healthy = os.path.join(source_path, 'Fruit_Healthy')\n",
        "source_path_fruit_woodiness = os.path.join(source_path, 'Fruit_Woodiness')\n",
        "source_path_leaves_brownspot = os.path.join(source_path, 'Leaves_Brownspot')\n",
        "source_path_leaves_healthy = os.path.join(source_path, 'Leaves_Healthy')\n",
        "source_path_leaves_woodiness = os.path.join(source_path, 'Leaves_Woodiness')\n",
        "\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_fruit_brownspot))} images of Fruit_Brownspot.\")\n",
        "print(f\"There are {len(os.listdir(source_path_fruit_healthy))} images of Fruit_Healthy.\")\n",
        "print(f\"There are {len(os.listdir(source_path_fruit_woodiness))} images of Fruit_Woodiness.\")\n",
        "print(f\"There are {len(os.listdir(source_path_leaves_brownspot))} images of Leaves_Brownspot.\")\n",
        "print(f\"There are {len(os.listdir(source_path_leaves_healthy))} images of Leaves_Healthy.\")\n",
        "print(f\"There are {len(os.listdir(source_path_leaves_woodiness))} images of Leaves_Woodiness.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3O7Vv2Zfyct",
        "outputId": "6cd15841-fa1c-4b7c-c1b5-6f0850513f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 921 images of Fruit_Brownspot.\n",
            "There are 1029 images of Fruit_Healthy.\n",
            "There are 1042 images of Fruit_Woodiness.\n",
            "There are 1052 images of Leaves_Brownspot.\n",
            "There are 1041 images of Leaves_Healthy.\n",
            "There are 1181 images of Leaves_Woodiness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define root directory\n",
        "root_dir = '/content/combined_dataset'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "def create_train_val_dirs(root_path):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "  \n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "  \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"  \n",
        "\n",
        "\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "\n",
        "  path = os.path.join(root_dir, 'training')\n",
        "  os.makedirs(path)\n",
        "  path_1 = os.path.join(path, 'fruit_brownspot')\n",
        "  os.makedirs(path_1)\n",
        "  path_2 = os.path.join(path, 'fruit_healthy')\n",
        "  os.makedirs(path_2)\n",
        "  path_3 = os.path.join(path, 'fruit_woodiness')\n",
        "  os.makedirs(path_3)\n",
        "  path_4 = os.path.join(path, 'leaves_brownspot')\n",
        "  os.makedirs(path_4)\n",
        "  path_5 = os.path.join(path, 'leaves_healthy')\n",
        "  os.makedirs(path_5)\n",
        "  path_6 = os.path.join(path, 'leaves_woodiness')\n",
        "  os.makedirs(path_6)\n",
        "  path_19 = os.path.join(path, 'unknown')\n",
        "  os.makedirs(path_19)\n",
        "  path = os.path.join(root_dir, 'validation')\n",
        "  os.makedirs(path)\n",
        "  path_7 = os.path.join(path, 'fruit_brownspot')\n",
        "  os.makedirs(path_7)\n",
        "  path_8 = os.path.join(path, 'fruit_healthy')\n",
        "  os.makedirs(path_8)\n",
        "  path_9 = os.path.join(path, 'fruit_woodiness')\n",
        "  os.makedirs(path_9)\n",
        "  path_10 = os.path.join(path, 'leaves_brownspot')\n",
        "  os.makedirs(path_10)\n",
        "  path_11 = os.path.join(path, 'leaves_healthy')\n",
        "  os.makedirs(path_11)\n",
        "  path_12 = os.path.join(path, 'leaves_woodiness')\n",
        "  os.makedirs(path_12)\n",
        "  path_20 = os.path.join(path, 'unknown')\n",
        "  os.makedirs(path_20)\n",
        "  path = os.path.join(root_dir, 'test')\n",
        "  os.makedirs(path)\n",
        "  path_13 = os.path.join(path, 'fruit_brownspot')\n",
        "  os.makedirs(path_13)\n",
        "  path_14 = os.path.join(path, 'fruit_healthy')\n",
        "  os.makedirs(path_14)\n",
        "  path_15 = os.path.join(path, 'fruit_woodiness')\n",
        "  os.makedirs(path_15)\n",
        "  path_16 = os.path.join(path, 'leaves_brownspot')\n",
        "  os.makedirs(path_16)\n",
        "  path_17 = os.path.join(path, 'leaves_healthy')\n",
        "  os.makedirs(path_17)\n",
        "  path_18 = os.path.join(path, 'leaves_woodiness')\n",
        "  os.makedirs(path_18)\n",
        "  path_21 = os.path.join(path, 'unknown')\n",
        "  os.makedirs(path_21)\n",
        "  \n",
        "\n",
        "  \n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "g95rZr2vgEPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your create_train_val_dirs function\n",
        "\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmxJJHeFgWly",
        "outputId": "0b650467-5726-4c8c-95cc-5c8a3284c926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/combined_dataset/training\n",
            "/content/combined_dataset/test\n",
            "/content/combined_dataset/validation\n",
            "/content/combined_dataset/training/unknown\n",
            "/content/combined_dataset/training/fruit_woodiness\n",
            "/content/combined_dataset/training/fruit_brownspot\n",
            "/content/combined_dataset/training/leaves_woodiness\n",
            "/content/combined_dataset/training/leaves_healthy\n",
            "/content/combined_dataset/training/fruit_healthy\n",
            "/content/combined_dataset/training/leaves_brownspot\n",
            "/content/combined_dataset/test/unknown\n",
            "/content/combined_dataset/test/fruit_woodiness\n",
            "/content/combined_dataset/test/fruit_brownspot\n",
            "/content/combined_dataset/test/leaves_woodiness\n",
            "/content/combined_dataset/test/leaves_healthy\n",
            "/content/combined_dataset/test/fruit_healthy\n",
            "/content/combined_dataset/test/leaves_brownspot\n",
            "/content/combined_dataset/validation/unknown\n",
            "/content/combined_dataset/validation/fruit_woodiness\n",
            "/content/combined_dataset/validation/fruit_brownspot\n",
            "/content/combined_dataset/validation/leaves_woodiness\n",
            "/content/combined_dataset/validation/leaves_healthy\n",
            "/content/combined_dataset/validation/fruit_healthy\n",
            "/content/combined_dataset/validation/leaves_brownspot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading unknown class data\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import uuid\n",
        "\n",
        "# Number of images to download for the unknown class\n",
        "n_images = 1000\n",
        "\n",
        "# The beans dataset\n",
        "dataset_name = \"beans\"\n",
        "\n",
        "# Root directory for the dataset\n",
        "root_dir = '/content/beans_dataset'\n",
        "\n",
        "# Create the unknown directory if it doesn't exist\n",
        "unknown_dir = os.path.join(root_dir, 'unknown')\n",
        "if not os.path.exists(unknown_dir):\n",
        "    os.makedirs(unknown_dir)\n",
        "\n",
        "# Download and extract the dataset\n",
        "ds, ds_info = tfds.load(\"beans\", split=\"train[:1000]\", with_info=True, as_supervised=True)\n",
        "\n",
        "# Iterate through the dataset and copy the images to the unknown directory\n",
        "for example in ds:\n",
        "    image_path = os.path.join(unknown_dir, f\"{str(uuid.uuid4())}.jpg\")\n",
        "    with open(image_path, 'wb') as f:\n",
        "        f.write(example['image'].numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "PQOiVLnx0j92",
        "outputId": "667a8df5-afe9-4593-d279-8451ac8b8081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-364fd796b2f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{str(uuid.uuid4())}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, TEST_DIR, SPLIT_SIZE):\n",
        "    \"\"\"\n",
        "    Splits the data into train, validation, and test sets.\n",
        "    \n",
        "    Args:\n",
        "        SOURCE_DIR (string): directory path containing the images\n",
        "        TRAINING_DIR (string): directory path to be used for training\n",
        "        VALIDATION_DIR (string): directory path to be used for validation\n",
        "        TEST_DIR (string): directory path to be used for test\n",
        "        SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Get list of all non-empty files in the source directory\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE_DIR):\n",
        "        file = SOURCE_DIR + filename\n",
        "        if os.path.getsize(file):\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print('{} is zero length, so ignoring.'.format(filename))\n",
        "    \n",
        "    # Shuffle and split the list into train, validation, and test sets\n",
        "    n_files = len(files)\n",
        "    split_p = int(n_files * SPLIT_SIZE)\n",
        "    test_p = int(n_files * 0.1)  # Use 10% of the dataset for the test set\n",
        "    shuffled = random.sample(files, n_files)\n",
        "    training_set = shuffled[:split_p]\n",
        "    validation_set = shuffled[split_p:split_p+test_p]\n",
        "    test_set = shuffled[split_p+test_p:]\n",
        "    \n",
        "    # Copy the files in the train, validation, and test sets to the appropriate directories\n",
        "    for filename in training_set:\n",
        "        source_file = SOURCE_DIR + filename\n",
        "        destination = TRAINING_DIR + filename\n",
        "        copyfile(source_file, destination)\n",
        "    for filename in validation_set:\n",
        "        source_file = SOURCE_DIR + filename\n",
        "        destination = VALIDATION_DIR + filename\n",
        "        copyfile(source_file, destination)\n",
        "    for filename in test_set:\n",
        "        source_file = SOURCE_DIR + filename\n",
        "        destination = TEST_DIR + filename\n",
        "        copyfile(source_file, destination)\n"
      ],
      "metadata": {
        "id": "1R7opxEFhsqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "FRUIT_BROWNSPOT_SOURCE_DIR = \"/content/katunda_classification/Fruit_Brownspot/\"\n",
        "FRUIT_HEALTHY_SOURCE_DIR = \"/content/katunda_classification/Fruit_Healthy/\"\n",
        "FRUIT_WOODINESS_SOURCE_DIR = \"/content/katunda_classification/Fruit_Woodiness/\"\n",
        "\n",
        "LEAVES_BROWNSPOT_SOURCE_DIR = \"/content/katunda_classification/Leaves_Brownspot/\"\n",
        "LEAVES_HEALTHY_SOURCE_DIR = \"/content/katunda_classification/Leaves_Healthy/\"\n",
        "LEAVES_WOODINESS_SOURCE_DIR = \"/content/katunda_classification/Leaves_Woodiness/\"\n",
        "\n",
        "TRAINING_DIR = \"/content/combined_dataset/training/\"\n",
        "VALIDATION_DIR = \"/content/combined_dataset/validation\"\n",
        "TEST_DIR = '/content/combined_dataset/test'\n",
        "\n",
        "TRAINING_FRUIT_BROWNSPOT_DIR = os.path.join(TRAINING_DIR, \"fruit_brownspot/\")\n",
        "VALIDATION_FRUIT_BROWNSPOT_DIR = os.path.join(VALIDATION_DIR, \"fruit_brownspot/\")\n",
        "TESTING_FRUIT_BROWNSPOT_DIR = os.path.join(TEST_DIR, \"fruit_brownspot/\")\n",
        "\n",
        "TRAINING_FRUIT_HEALTHY_DIR = os.path.join(TRAINING_DIR, \"fruit_healthy/\")\n",
        "VALIDATION_FRUIT_HEALTHY_DIR = os.path.join(VALIDATION_DIR, \"fruit_healthy/\")\n",
        "TESTING_FRUIT_HEALTHY_DIR = os.path.join(TEST_DIR, \"fruit_healthy/\")\n",
        "\n",
        "TRAINING_FRUIT_WOODINESS_DIR = os.path.join(TRAINING_DIR, \"fruit_woodiness/\")\n",
        "VALIDATION_FRUIT_WOODINESS_DIR = os.path.join(VALIDATION_DIR, \"fruit_woodiness/\")\n",
        "TESTING_FRUIT_WOODINESS_DIR = os.path.join(TEST_DIR, \"fruit_woodiness/\")\n",
        "\n",
        "TRAINING_LEAVES_BROWNSPOT_DIR = os.path.join(TRAINING_DIR, \"leaves_brownspot/\")\n",
        "VALIDATION_LEAVES_BROWNSPOT_DIR = os.path.join(VALIDATION_DIR, \"leaves_brownspot/\")\n",
        "TESTING_LEAVES_BROWNSPOT_DIR = os.path.join(TEST_DIR, \"leaves_brownspot/\")\n",
        "\n",
        "TRAINING_LEAVES_HEALTHY_DIR = os.path.join(TRAINING_DIR, \"leaves_healthy/\")\n",
        "VALIDATION_LEAVES_HEALTHY_DIR = os.path.join(VALIDATION_DIR, \"leaves_healthy/\")\n",
        "TESTING_LEAVES_HEALTHY_DIR = os.path.join(TEST_DIR, \"leaves_healthy/\")\n",
        "\n",
        "TRAINING_LEAVES_WOODINESS_DIR = os.path.join(TRAINING_DIR, \"leaves_woodiness/\")\n",
        "VALIDATION_LEAVES_WOODINESS_DIR = os.path.join(VALIDATION_DIR, \"leaves_woodiness/\")\n",
        "TESTING_LEAVES_WOODINESS_DIR = os.path.join(TEST_DIR, \"leaves_woodiness/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_FRUIT_BROWNSPOT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_FRUIT_BROWNSPOT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_FRUIT_HEALTHY_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_FRUIT_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_FRUIT_WOODINESS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_FRUIT_WOODINESS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_LEAVES_BROWNSPOT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_LEAVES_BROWNSPOT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_LEAVES_HEALTHY_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_LEAVES_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_LEAVES_WOODINESS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_LEAVES_WOODINESS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "if len(os.listdir(VALIDATION_FRUIT_BROWNSPOT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_FRUIT_BROWNSPOT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_FRUIT_HEALTHY_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_FRUIT_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_FRUIT_WOODINESS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_FRUIT_WOODINESS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_LEAVES_BROWNSPOT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_LEAVES_BROWNSPOT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_LEAVES_HEALTHY_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_LEAVES_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_LEAVES_WOODINESS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_LEAVES_WOODINESS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(TESTING_FRUIT_BROWNSPOT_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_FRUIT_BROWNSPOT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_FRUIT_HEALTHY_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_FRUIT_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_FRUIT_WOODINESS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_FRUIT_WOODINESS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_LEAVES_BROWNSPOT_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_LEAVES_BROWNSPOT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_LEAVES_HEALTHY_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_LEAVES_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_LEAVES_WOODINESS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_LEAVES_WOODINESS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .7\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(FRUIT_BROWNSPOT_SOURCE_DIR, TRAINING_FRUIT_BROWNSPOT_DIR, VALIDATION_FRUIT_BROWNSPOT_DIR, TESTING_FRUIT_BROWNSPOT_DIR, split_size)\n",
        "split_data(FRUIT_HEALTHY_SOURCE_DIR, TRAINING_FRUIT_HEALTHY_DIR, VALIDATION_FRUIT_HEALTHY_DIR, TESTING_FRUIT_HEALTHY_DIR, split_size)\n",
        "split_data(FRUIT_WOODINESS_SOURCE_DIR, TRAINING_FRUIT_WOODINESS_DIR, VALIDATION_FRUIT_WOODINESS_DIR, TESTING_FRUIT_WOODINESS_DIR, split_size)\n",
        "split_data(LEAVES_BROWNSPOT_SOURCE_DIR, TRAINING_LEAVES_BROWNSPOT_DIR, VALIDATION_LEAVES_BROWNSPOT_DIR, TESTING_LEAVES_BROWNSPOT_DIR, split_size)\n",
        "split_data(LEAVES_HEALTHY_SOURCE_DIR, TRAINING_LEAVES_HEALTHY_DIR, VALIDATION_LEAVES_HEALTHY_DIR, TESTING_LEAVES_HEALTHY_DIR, split_size)\n",
        "split_data(LEAVES_WOODINESS_SOURCE_DIR, TRAINING_LEAVES_WOODINESS_DIR, VALIDATION_LEAVES_WOODINESS_DIR, TESTING_LEAVES_WOODINESS_DIR, split_size)\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal fruit brownspot's directory has {len(os.listdir(FRUIT_BROWNSPOT_SOURCE_DIR))} images\")\n",
        "print(f\"Original fruit healthy's directory has {len(os.listdir(FRUIT_HEALTHY_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original fruit woodiness's directory has {len(os.listdir(FRUIT_WOODINESS_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original leaves brownspot's directory has {len(os.listdir(LEAVES_BROWNSPOT_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original leaves healthy's directory has {len(os.listdir(LEAVES_HEALTHY_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original leaves woodiness's directory has {len(os.listdir(LEAVES_WOODINESS_SOURCE_DIR))} images\\n\")\n",
        "\n",
        "# Training and validation splits. Check that the number of images matches the expected output.\n",
        "print(f\"There are {len(os.listdir(TRAINING_FRUIT_BROWNSPOT_DIR))} images of fruit brownspot for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_FRUIT_HEALTHY_DIR))} images of fruit healthy for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_FRUIT_WOODINESS_DIR))} images of fruit woodiness for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_LEAVES_BROWNSPOT_DIR))} images of leaves brownspot for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_LEAVES_BROWNSPOT_DIR))} images of leaves healthy for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_LEAVES_BROWNSPOT_DIR))} images of leaves woodiness for training\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(VALIDATION_FRUIT_BROWNSPOT_DIR))} images of fruit brownspot for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_FRUIT_HEALTHY_DIR))} images of fruit healthy for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_FRUIT_WOODINESS_DIR))} images of fruit woodiness for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_LEAVES_BROWNSPOT_DIR))} images of leaves brownspot for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_LEAVES_HEALTHY_DIR))} images of leaves healthy for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_LEAVES_WOODINESS_DIR))} images of leaves woodiness for validation\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(TESTING_FRUIT_BROWNSPOT_DIR))} images of fruit brownspot for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_FRUIT_HEALTHY_DIR))} images of fruit healthy for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_FRUIT_WOODINESS_DIR))} images of fruit woodiness for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_LEAVES_BROWNSPOT_DIR))} images of leaves brownspot for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_LEAVES_HEALTHY_DIR))} images of leaves healthy for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_LEAVES_WOODINESS_DIR))} images of leaves woodiness for testing\")"
      ],
      "metadata": {
        "id": "RmSazLxXz3Bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b81f47-9bd6-4846-c05c-d3e92103ba11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original fruit brownspot's directory has 921 images\n",
            "Original fruit healthy's directory has 1029 images\n",
            "\n",
            "Original fruit woodiness's directory has 1042 images\n",
            "\n",
            "Original leaves brownspot's directory has 1052 images\n",
            "\n",
            "Original leaves healthy's directory has 1041 images\n",
            "\n",
            "Original leaves woodiness's directory has 1181 images\n",
            "\n",
            "There are 644 images of fruit brownspot for training\n",
            "There are 720 images of fruit healthy for training\n",
            "There are 729 images of fruit woodiness for training\n",
            "There are 736 images of leaves brownspot for training\n",
            "There are 736 images of leaves healthy for training\n",
            "There are 736 images of leaves woodiness for training\n",
            "There are 92 images of fruit brownspot for validation\n",
            "There are 102 images of fruit healthy for validation\n",
            "There are 104 images of fruit woodiness for validation\n",
            "There are 105 images of leaves brownspot for validation\n",
            "There are 104 images of leaves healthy for validation\n",
            "There are 118 images of leaves woodiness for validation\n",
            "There are 185 images of fruit brownspot for testing\n",
            "There are 207 images of fruit healthy for testing\n",
            "There are 209 images of fruit woodiness for testing\n",
            "There are 211 images of leaves brownspot for testing\n",
            "There are 209 images of leaves healthy for testing\n",
            "There are 237 images of leaves woodiness for testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR):\n",
        "    \"\"\"\n",
        "    Creates the training, validation, and test data generators.\n",
        "    \n",
        "    Args:\n",
        "        TRAINING_DIR (string): directory path containing the training images\n",
        "        VALIDATION_DIR (string): directory path containing the validation images\n",
        "        TEST_DIR (string): directory path containing the test images\n",
        "    \n",
        "    Returns:\n",
        "        train_generator, validation_generator, test_generator - tuple containing the generators\n",
        "    \"\"\"\n",
        "    # Instantiate the ImageDataGenerator class for the training set\n",
        "    # (don't forget to set the arguments to augment the images)\n",
        "    train_datagen = ImageDataGenerator(rescale=1.0/255.,\n",
        "                                      rotation_range=40,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')\n",
        "    \n",
        "    # Use the flow_from_directory method to create a generator for the training set\n",
        "    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        target_size=(224, 224))\n",
        "    \n",
        "    # Instantiate the ImageDataGenerator class for the validation set\n",
        "    # (don't forget to set the rescale argument)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "    \n",
        "    # Use the flow_from_directory method to create a generator for the validation set\n",
        "    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  target_size=(224, 224))\n",
        "    \n",
        "    # Instantiate the ImageDataGenerator class for the test set\n",
        "    # (don't forget to set the rescale argument)\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "\n",
        "    # Use the flow_from_directory method to create a generator for the validation set\n",
        "    test_generator = test_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  target_size=(224, 224))\n",
        "    \n",
        "    return train_generator, validation_generator, test_generator\n"
      ],
      "metadata": {
        "id": "CvCGEz8MCb6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, validation_generator, test_generator = train_val_test_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIFlYhtoFMV8",
        "outputId": "d82af5f4-eef8-4c8c-e711-0ca8af16c2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4383 images belonging to 6 classes.\n",
            "Found 625 images belonging to 6 classes.\n",
            "Found 1258 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Define the input shape of your model\n",
        "    input_shape = (224, 224, 3)\n",
        "\n",
        "    # Add convolutional layers to your model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(6, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile your model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "X7n6u_v4Fm5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so0AA49viRr-",
        "outputId": "45a39424-541d-45de-ae07-ae5311c4315d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "137/137 [==============================] - 122s 860ms/step - loss: 1.8042 - accuracy: 0.2010 - val_loss: 1.6120 - val_accuracy: 0.3376\n",
            "Epoch 2/15\n",
            "137/137 [==============================] - 114s 835ms/step - loss: 1.5973 - accuracy: 0.3356 - val_loss: 1.5367 - val_accuracy: 0.3808\n",
            "Epoch 3/15\n",
            "137/137 [==============================] - 116s 848ms/step - loss: 1.4767 - accuracy: 0.3947 - val_loss: 1.4065 - val_accuracy: 0.4736\n",
            "Epoch 4/15\n",
            "137/137 [==============================] - 112s 820ms/step - loss: 1.4119 - accuracy: 0.4301 - val_loss: 1.3361 - val_accuracy: 0.5040\n",
            "Epoch 5/15\n",
            "137/137 [==============================] - 113s 828ms/step - loss: 1.3167 - accuracy: 0.4985 - val_loss: 1.4433 - val_accuracy: 0.4720\n",
            "Epoch 6/15\n",
            "137/137 [==============================] - 115s 836ms/step - loss: 1.1630 - accuracy: 0.5661 - val_loss: 0.8311 - val_accuracy: 0.6992\n",
            "Epoch 7/15\n",
            "137/137 [==============================] - 113s 826ms/step - loss: 0.9061 - accuracy: 0.6619 - val_loss: 0.7710 - val_accuracy: 0.7184\n",
            "Epoch 8/15\n",
            "137/137 [==============================] - 116s 844ms/step - loss: 0.8382 - accuracy: 0.7045 - val_loss: 0.6783 - val_accuracy: 0.7648\n",
            "Epoch 9/15\n",
            "137/137 [==============================] - 113s 827ms/step - loss: 0.7519 - accuracy: 0.7294 - val_loss: 0.6215 - val_accuracy: 0.7824\n",
            "Epoch 10/15\n",
            "137/137 [==============================] - 114s 834ms/step - loss: 0.6826 - accuracy: 0.7543 - val_loss: 0.5171 - val_accuracy: 0.8224\n",
            "Epoch 11/15\n",
            "137/137 [==============================] - 113s 823ms/step - loss: 0.6235 - accuracy: 0.7732 - val_loss: 0.4654 - val_accuracy: 0.8480\n",
            "Epoch 12/15\n",
            "137/137 [==============================] - 115s 835ms/step - loss: 0.5991 - accuracy: 0.7862 - val_loss: 0.3951 - val_accuracy: 0.8640\n",
            "Epoch 13/15\n",
            "137/137 [==============================] - 115s 837ms/step - loss: 0.5180 - accuracy: 0.8088 - val_loss: 0.4722 - val_accuracy: 0.8336\n",
            "Epoch 14/15\n",
            "137/137 [==============================] - 115s 837ms/step - loss: 0.4883 - accuracy: 0.8275 - val_loss: 0.3684 - val_accuracy: 0.8720\n",
            "Epoch 15/15\n",
            "137/137 [==============================] - 115s 841ms/step - loss: 0.4464 - accuracy: 0.8396 - val_loss: 0.4770 - val_accuracy: 0.8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSHO0-XnqM5z",
        "outputId": "adc8c2c3-d1cd-4ead-89cd-4e94a84c53dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "137/137 [==============================] - 116s 843ms/step - loss: 1.5279 - accuracy: 0.3292 - val_loss: 1.2022 - val_accuracy: 0.5088\n",
            "Epoch 2/50\n",
            "137/137 [==============================] - 120s 877ms/step - loss: 1.3000 - accuracy: 0.4652 - val_loss: 1.3479 - val_accuracy: 0.4368\n",
            "Epoch 3/50\n",
            "137/137 [==============================] - 117s 853ms/step - loss: 1.1550 - accuracy: 0.5453 - val_loss: 1.0208 - val_accuracy: 0.6112\n",
            "Epoch 4/50\n",
            "137/137 [==============================] - 117s 851ms/step - loss: 1.0611 - accuracy: 0.5925 - val_loss: 0.9868 - val_accuracy: 0.6272\n",
            "Epoch 5/50\n",
            "137/137 [==============================] - 114s 831ms/step - loss: 0.9331 - accuracy: 0.6621 - val_loss: 0.9148 - val_accuracy: 0.6624\n",
            "Epoch 6/50\n",
            "137/137 [==============================] - 116s 847ms/step - loss: 0.8923 - accuracy: 0.6669 - val_loss: 0.9060 - val_accuracy: 0.6688\n",
            "Epoch 7/50\n",
            "137/137 [==============================] - 114s 832ms/step - loss: 0.8231 - accuracy: 0.6936 - val_loss: 0.8080 - val_accuracy: 0.7392\n",
            "Epoch 8/50\n",
            "137/137 [==============================] - 116s 849ms/step - loss: 0.7657 - accuracy: 0.7175 - val_loss: 0.6674 - val_accuracy: 0.7632\n",
            "Epoch 9/50\n",
            "137/137 [==============================] - 116s 846ms/step - loss: 0.7311 - accuracy: 0.7262 - val_loss: 0.5900 - val_accuracy: 0.7952\n",
            "Epoch 10/50\n",
            "137/137 [==============================] - 114s 828ms/step - loss: 0.6541 - accuracy: 0.7629 - val_loss: 0.5232 - val_accuracy: 0.8192\n",
            "Epoch 11/50\n",
            "137/137 [==============================] - 113s 827ms/step - loss: 0.6044 - accuracy: 0.7794 - val_loss: 0.6083 - val_accuracy: 0.7744\n",
            "Epoch 12/50\n",
            "137/137 [==============================] - 118s 864ms/step - loss: 0.5209 - accuracy: 0.8131 - val_loss: 0.3803 - val_accuracy: 0.8688\n",
            "Epoch 13/50\n",
            "137/137 [==============================] - 120s 875ms/step - loss: 0.4958 - accuracy: 0.8239 - val_loss: 0.4192 - val_accuracy: 0.8512\n",
            "Epoch 14/50\n",
            "137/137 [==============================] - 114s 835ms/step - loss: 0.4372 - accuracy: 0.8442 - val_loss: 0.3641 - val_accuracy: 0.8736\n",
            "Epoch 15/50\n",
            "137/137 [==============================] - 114s 834ms/step - loss: 0.3876 - accuracy: 0.8681 - val_loss: 0.3346 - val_accuracy: 0.8992\n",
            "Epoch 16/50\n",
            "137/137 [==============================] - 113s 826ms/step - loss: 0.3642 - accuracy: 0.8693 - val_loss: 0.2791 - val_accuracy: 0.9024\n",
            "Epoch 17/50\n",
            "137/137 [==============================] - 114s 835ms/step - loss: 0.3488 - accuracy: 0.8770 - val_loss: 0.3153 - val_accuracy: 0.8912\n",
            "Epoch 18/50\n",
            "137/137 [==============================] - 119s 871ms/step - loss: 0.3296 - accuracy: 0.8827 - val_loss: 0.2329 - val_accuracy: 0.9168\n",
            "Epoch 19/50\n",
            "137/137 [==============================] - 120s 874ms/step - loss: 0.3374 - accuracy: 0.8784 - val_loss: 0.2747 - val_accuracy: 0.9088\n",
            "Epoch 20/50\n",
            "137/137 [==============================] - 115s 837ms/step - loss: 0.2774 - accuracy: 0.9028 - val_loss: 0.2942 - val_accuracy: 0.9040\n",
            "Epoch 21/50\n",
            "137/137 [==============================] - 115s 841ms/step - loss: 0.3220 - accuracy: 0.8909 - val_loss: 0.3495 - val_accuracy: 0.8752\n",
            "Epoch 22/50\n",
            "137/137 [==============================] - 114s 829ms/step - loss: 0.2809 - accuracy: 0.9024 - val_loss: 0.2208 - val_accuracy: 0.9280\n",
            "Epoch 23/50\n",
            "137/137 [==============================] - 115s 840ms/step - loss: 0.2586 - accuracy: 0.9122 - val_loss: 0.1865 - val_accuracy: 0.9424\n",
            "Epoch 24/50\n",
            "137/137 [==============================] - 114s 830ms/step - loss: 0.2507 - accuracy: 0.9151 - val_loss: 0.3015 - val_accuracy: 0.9104\n",
            "Epoch 25/50\n",
            "137/137 [==============================] - 114s 832ms/step - loss: 0.2552 - accuracy: 0.9122 - val_loss: 0.2111 - val_accuracy: 0.9280\n",
            "Epoch 26/50\n",
            "137/137 [==============================] - 120s 879ms/step - loss: 0.2176 - accuracy: 0.9213 - val_loss: 0.1810 - val_accuracy: 0.9280\n",
            "Epoch 27/50\n",
            "137/137 [==============================] - 115s 840ms/step - loss: 0.2187 - accuracy: 0.9233 - val_loss: 0.1681 - val_accuracy: 0.9424\n",
            "Epoch 28/50\n",
            "137/137 [==============================] - 113s 826ms/step - loss: 0.2091 - accuracy: 0.9238 - val_loss: 0.2711 - val_accuracy: 0.9024\n",
            "Epoch 29/50\n",
            "137/137 [==============================] - 114s 831ms/step - loss: 0.2308 - accuracy: 0.9201 - val_loss: 0.1807 - val_accuracy: 0.9328\n",
            "Epoch 30/50\n",
            "137/137 [==============================] - 112s 817ms/step - loss: 0.1852 - accuracy: 0.9368 - val_loss: 0.1765 - val_accuracy: 0.9456\n",
            "Epoch 31/50\n",
            "137/137 [==============================] - 112s 819ms/step - loss: 0.2020 - accuracy: 0.9293 - val_loss: 0.3691 - val_accuracy: 0.8848\n",
            "Epoch 32/50\n",
            "137/137 [==============================] - 111s 811ms/step - loss: 0.2171 - accuracy: 0.9249 - val_loss: 0.2099 - val_accuracy: 0.9328\n",
            "Epoch 33/50\n",
            "137/137 [==============================] - 111s 812ms/step - loss: 0.1911 - accuracy: 0.9354 - val_loss: 0.1831 - val_accuracy: 0.9280\n",
            "Epoch 34/50\n",
            "137/137 [==============================] - 109s 798ms/step - loss: 0.1797 - accuracy: 0.9379 - val_loss: 0.1972 - val_accuracy: 0.9296\n",
            "Epoch 35/50\n",
            "137/137 [==============================] - 112s 819ms/step - loss: 0.1669 - accuracy: 0.9418 - val_loss: 0.1821 - val_accuracy: 0.9472\n",
            "Epoch 36/50\n",
            "137/137 [==============================] - 111s 807ms/step - loss: 0.1697 - accuracy: 0.9411 - val_loss: 0.3189 - val_accuracy: 0.9008\n",
            "Epoch 37/50\n",
            "137/137 [==============================] - 111s 808ms/step - loss: 0.1924 - accuracy: 0.9375 - val_loss: 0.1956 - val_accuracy: 0.9248\n",
            "Epoch 38/50\n",
            "137/137 [==============================] - 113s 828ms/step - loss: 0.1717 - accuracy: 0.9411 - val_loss: 0.1822 - val_accuracy: 0.9344\n",
            "Epoch 39/50\n",
            "137/137 [==============================] - 111s 813ms/step - loss: 0.1640 - accuracy: 0.9480 - val_loss: 0.1436 - val_accuracy: 0.9536\n",
            "Epoch 40/50\n",
            "137/137 [==============================] - 113s 822ms/step - loss: 0.1592 - accuracy: 0.9482 - val_loss: 0.1281 - val_accuracy: 0.9488\n",
            "Epoch 41/50\n",
            "137/137 [==============================] - 111s 813ms/step - loss: 0.1432 - accuracy: 0.9500 - val_loss: 0.1234 - val_accuracy: 0.9584\n",
            "Epoch 42/50\n",
            "137/137 [==============================] - 113s 822ms/step - loss: 0.1611 - accuracy: 0.9471 - val_loss: 0.1379 - val_accuracy: 0.9568\n",
            "Epoch 43/50\n",
            "137/137 [==============================] - 111s 813ms/step - loss: 0.1291 - accuracy: 0.9560 - val_loss: 0.1584 - val_accuracy: 0.9488\n",
            "Epoch 44/50\n",
            "137/137 [==============================] - 112s 814ms/step - loss: 0.1439 - accuracy: 0.9514 - val_loss: 0.1274 - val_accuracy: 0.9584\n",
            "Epoch 45/50\n",
            "137/137 [==============================] - 114s 829ms/step - loss: 0.1168 - accuracy: 0.9596 - val_loss: 0.1455 - val_accuracy: 0.9520\n",
            "Epoch 46/50\n",
            "137/137 [==============================] - 113s 821ms/step - loss: 0.1542 - accuracy: 0.9471 - val_loss: 0.1369 - val_accuracy: 0.9424\n",
            "Epoch 47/50\n",
            "137/137 [==============================] - 112s 821ms/step - loss: 0.1660 - accuracy: 0.9416 - val_loss: 0.2195 - val_accuracy: 0.9328\n",
            "Epoch 48/50\n",
            "137/137 [==============================] - 112s 817ms/step - loss: 0.1277 - accuracy: 0.9576 - val_loss: 0.1643 - val_accuracy: 0.9456\n",
            "Epoch 49/50\n",
            "137/137 [==============================] - 112s 813ms/step - loss: 0.1234 - accuracy: 0.9598 - val_loss: 0.1750 - val_accuracy: 0.9472\n",
            "Epoch 50/50\n",
            "137/137 [==============================] - 113s 822ms/step - loss: 0.1161 - accuracy: 0.9626 - val_loss: 0.1330 - val_accuracy: 0.9616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdDzwzwGvjUg",
        "outputId": "31454669-851e-4d20-fa86-97d6689453e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 18s 452ms/step - loss: 0.1000 - accuracy: 0.9603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('katunda_model_v1.h5')"
      ],
      "metadata": {
        "id": "b38_UhAz1pjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(test_generator) # predict probabilities\n",
        "y_pred = [int(round(i[0])) for i in prediction] # converting probabilities to binary outputs"
      ],
      "metadata": {
        "id": "w1kslhzHyNMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PwIqzwQ1yS69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "    normalize=False,\n",
        "    title='Confusion matrix',\n",
        "    cmap=pyplot.cm.Blues\n",
        "):\n",
        "    \n",
        "    pyplot.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    pyplot.title(title)\n",
        "    pyplot.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    pyplot.xticks(tick_marks, classes, rotation=45)\n",
        "    pyplot.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    print(cm)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        pyplot.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "        horizontalalignment=\"center\",\n",
        "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    pyplot.tight_layout()\n",
        "    pyplot.ylabel('True label')\n",
        "    pyplot.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "x6IZY0wXyXKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iz34IyPRyc0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ddq1cNzorEzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hy_TpCamrIl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}