{"cells":[{"cell_type":"markdown","metadata":{"id":"QuS9B_yNN1F9"},"source":["# Katunda Fruits Classification\n","---\n","In this notebook, we train a **CNN** to classify images from the Katunda-classification dataset.\n","\n","The images in this dataset are fruit images images of passion fruits that fall into one of three(3) classes; \n","* Brown Spot\n","* Healthy\n","* Woodiness\n",".\n","\n","Code written by `Ochieng Tony Blair` and `Olwa Micheal Okaka` of [The Marconi Society Machine Learning Laboratory](https://marconilab.org/)\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40621,"status":"ok","timestamp":1655627956414,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"_10K2Mchb8l-","outputId":"9a9e1394-e327-47f7-fa3b-c10b0ab47466"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1655627959968,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"iHeF9TfCbylb"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/intern')"]},{"cell_type":"markdown","metadata":{"id":"eHsT-k-FQzxj"},"source":["### Test for CUDA"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2395,"status":"ok","timestamp":1655627970781,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"s_NNq5biMkiO","outputId":"58f9d953-2b7a-47a1-e12e-b7e32c352b53"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available! Training on GPU ...\n"]}],"source":["import torch\n","import numpy as np\n","\n","# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","  print('CUDA is not available. Training on CPU ...')\n","else:\n","  print('CUDA is available! Training on GPU ...')"]},{"cell_type":"markdown","metadata":{"id":"3qpLuPKXSBXn"},"source":["---\n","## Load the Data\n","\n","We load in the training and test data, split the training data into a training and validation set, then create DataLoaders for each of these sets of data."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":558,"status":"ok","timestamp":1655628205438,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"QOQSFYWrR6k7"},"outputs":[],"source":["from torchvision.transforms.transforms import Resize\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","# number of subprocesses to use for data loading\n","num_workers = 0\n","# how many samples per batch to load\n","batch_size = 32\n","# percentage of traing set to use as validation\n","valid_size = 0.2\n","\n","#convert data to a normalized torch.FloatTensor\n","train_transforms = transforms.Compose([transforms.Resize(224),\n","                                       transforms.RandomRotation(20),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.RandomVerticalFlip(),\n","                                       transforms.RandomRotation(10),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.5, 0.5,  0.5],\n","                                                            [0.5, 0.5, 0.5])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(224),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.RandomVerticalFlip(),\n","                                      transforms.RandomRotation(10),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.5, 0.5,  0.5],\n","                                                           [0.5, 0.5, 0.5])])\n","\n","# choose the training and test datasets\n","data_dir = '/content/drive/MyDrive/intern/introduction_to_pytorch/intro-to-pytorch/sample_fruits'\n","\n","# Pass transforms in here after loading dataset\n","train_data = datasets.ImageFolder(data_dir + '/training', transform=train_transforms)\n","test_data = datasets.ImageFolder(data_dir + '/validation', transform=test_transforms)\n","\n","# Obtain training indices to be used for validation\n","num_train = len(train_data)\n","indices = list(range(num_train))\n","np.random.shuffle(indices)\n","split = int(np.floor(valid_size * num_train))\n","train_idx, valid_idx = indices[split:], indices[:split]\n","\n","# define samplers for obtaining training and validation batches\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","# prepare data loaders (combine dataset and sampler)\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers )\n","valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n","\n","#specify the classes\n","classes = ['BrownSpot', 'Healthy', 'Woodiness']\n"]},{"cell_type":"markdown","metadata":{"id":"-L7GwpE8ZQjL"},"source":["### Visualize a Batch of Training Data"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1655626138134,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"NoN3yqGwZPpR"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# helper fuction to un-normalize and disply an image\n","def imshow(img):\n","  img = img/2 + 0.5 #\n","  plt.imshow(np.transpose(img, (1,2,0))) # convert from Tensor image"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":936,"output_embedded_package_id":"15MB2RDZUaOsclU8IHM3b2fVr0zFegavX"},"executionInfo":{"elapsed":19964,"status":"ok","timestamp":1655626158092,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"2P6uY_ctaGPC","outputId":"4f24453c-8c68-4f65-f190-6a6ea7dc6bae"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["# obtain one batch from training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","#plot the images in the batch with labels\n","fig = plt.figure(figsize=(25, 25))\n","#display 20 images\n","for idx in np.arange(20):\n","  ax = fig.add_subplot(4, 5, idx+1, xticks=[], yticks=[])\n","  imshow(images[idx])\n","  ax.set_title(classes[labels[idx]])"]},{"cell_type":"markdown","metadata":{"id":"VwAniBdoeVxs"},"source":["### View an Image in More Detail\n","\n","Here, we look at the normalized red, green, and blue (RGB) color channels as three separate, grayscale intensity images."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1655626158096,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"YAIDO8z5cnXf"},"outputs":[],"source":["# rgb_img = np.squeeze(images[3])\n","# channels = ['red channel', 'green channel', 'blue channel']\n","\n","# fig = plt.figure(figsize = (36, 36)) \n","# for idx in np.arange(rgb_img.shape[0]):\n","#     ax = fig.add_subplot(1, 3, idx + 1)\n","#     img = rgb_img[idx]\n","#     ax.imshow(img, cmap='gray')\n","#     ax.set_title(channels[idx])\n","#     width, height = img.shape\n","#     thresh = img.max()/2.5\n","#     for x in range(width):\n","#         for y in range(height):\n","#             val = round(img[x][y],2) if img[x][y] !=0 else 0\n","#             ax.annotate(str(val), xy=(y,x),\n","#                     horizontalalignment='center',\n","#                     verticalalignment='center', size=8,\n","#                     color='white' if img[x][y]\u003cthresh else 'black')"]},{"cell_type":"markdown","metadata":{"id":"uSEuwYYkfYEi"},"source":["---\n","## Define the Network Architecture"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12631,"status":"ok","timestamp":1655628017607,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"aPz5z5-Gf4C8","outputId":"7ad4cfae-4d25-4517-c16c-0288f51f66c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Net(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=256, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=3, bias=True)\n","  (dropout): Dropout(p=0.25, inplace=False)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# define the CNN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # covolutional layers\n","        self.conv1 = nn.Conv2d(3, 32, 3)\n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        self.conv3 = nn.Conv2d(64, 64, 3)\n","        self.conv4 = nn.Conv2d(64, 64, 3)\n","        self.conv5 = nn.Conv2d(64, 64, 3)\n","        self.conv6 = nn.Conv2d(64, 64, 3)\n","        self.conv7 = nn.Conv2d(64, 64, 3)\n","        self.conv8 = nn.Conv2d(64, 64, 3)\n","        # max pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        self.fc1 = nn.Linear(256, 64)\n","        self.fc2 = nn.Linear(64, 3)\n","        # dropout layer (p=0.25)\n","        self.dropout = nn.Dropout(0.25)\n","\n","    def forward(self, x):\n","        #print(x.shape)\n","        # add sequence of convolutional and max pooling layers\n","        x = self.pool(F.relu(self.conv1(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv2(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv3(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv4(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv5(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv6(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv7(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv8(x)))\n","        #print(x.shape)\n","        # flatten image input\n","        x = x.view(-1, 256)\n","        #print(x.shape)\n","        # add dropout layer\n","        x = self.dropout(x)\n","        # add 1st hidden layer, with relu activation function\n","        x = F.relu(self.fc1(x))\n","        # add dropout layer\n","        x = self.dropout(x)\n","        x = F.softmax(self.fc2(x), dim =1)\n","        #print(x.shape)\n","        return x\n","\n","# create a complete CNN\n","model = Net()\n","print(model)\n","\n","# move tensors to GPU if CUDA is available\n","if train_on_gpu:\n","    model.cuda()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":778,"status":"ok","timestamp":1655628223983,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"-96X70cbBJ60","outputId":"a0fdc974-aae2-4940-c44e-49e494e18f37"},"outputs":[{"name":"stdout","output_type":"stream","text":["Net(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=64, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=3, bias=True)\n","  (dropout): Dropout(p=0.25, inplace=False)\n",")\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# define the CNN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # covolutional layers\n","        self.conv1 = nn.Conv2d(3, 32, 3)\n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        self.conv3 = nn.Conv2d(64, 64, 3)\n","        self.conv4 = nn.Conv2d(64, 64, 3)\n","        self.conv5 = nn.Conv2d(64, 64, 3)\n","        self.conv6 = nn.Conv2d(64, 64, 3)\n","        # max pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        self.fc1 = nn.Linear(64, 64)\n","        self.fc2 = nn.Linear(64, 3)\n","        # dropout layer (p=0.25)\n","        self.dropout = nn.Dropout(0.25)\n","\n","    def forward(self, x):\n","        #print(x.shape)\n","        # add sequence of convolutional and max pooling layers\n","        x = self.pool(F.relu(self.conv1(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv2(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv3(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv4(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv5(x)))\n","        #print(x.shape)\n","        x = self.pool(F.relu(self.conv6(x)))\n","        #print(x.shape)\n","        # flatten image input\n","        x = x.view(-1, 64)\n","        #print(x.shape)\n","        # add dropout layer\n","        x = self.dropout(x)\n","        # add 1st hidden layer, with relu activation function\n","        x = F.relu(self.fc1(x))\n","        # add dropout layer\n","        x = self.dropout(x)\n","        x = F.softmax(self.fc2(x), dim =1)\n","        #print(x.shape)\n","        return x\n","\n","# create a complete CNN\n","model = Net()\n","print(model)\n","\n","# move tensors to GPU if CUDA is available\n","if train_on_gpu:\n","    model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"F37USjkKhhda"},"source":["### Specify Loss Function and Optimizer\n","\n","Decide on a loss and optimization function that is best suited for this classification task."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":551,"status":"ok","timestamp":1655628234460,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"R2BieZUUhgdj"},"outputs":[],"source":["import torch.optim as optim\n","\n","# specify loss function (categorical cross-entropy)\n","criterion = nn.CrossEntropyLoss()\n","\n","# specify optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"x5rZA9FfiEP7"},"source":["---\n","## Train the Network\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2hzpnKsgiMS-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 \tTraining Loss: 1.075416 \tValidation Loss: 1.005846\n","Validation loss decreased (inf --\u003e 1.005846).  Saving model ...\n","Epoch: 2 \tTraining Loss: 1.003610 \tValidation Loss: 1.021439\n","Epoch: 3 \tTraining Loss: 0.993109 \tValidation Loss: 1.125402\n","Epoch: 4 \tTraining Loss: 1.003859 \tValidation Loss: 1.023705\n","Epoch: 5 \tTraining Loss: 0.981973 \tValidation Loss: 0.983010\n","Validation loss decreased (1.005846 --\u003e 0.983010).  Saving model ...\n","Epoch: 6 \tTraining Loss: 0.984467 \tValidation Loss: 0.997794\n","Epoch: 7 \tTraining Loss: 0.963032 \tValidation Loss: 1.050752\n","Epoch: 8 \tTraining Loss: 0.956513 \tValidation Loss: 1.027887\n","Epoch: 9 \tTraining Loss: 0.942586 \tValidation Loss: 0.981873\n","Validation loss decreased (0.983010 --\u003e 0.981873).  Saving model ...\n","Epoch: 10 \tTraining Loss: 0.918603 \tValidation Loss: 1.002941\n","Epoch: 11 \tTraining Loss: 0.962830 \tValidation Loss: 1.003008\n","Epoch: 12 \tTraining Loss: 0.962111 \tValidation Loss: 0.946921\n","Validation loss decreased (0.981873 --\u003e 0.946921).  Saving model ...\n","Epoch: 13 \tTraining Loss: 0.918230 \tValidation Loss: 0.946114\n","Validation loss decreased (0.946921 --\u003e 0.946114).  Saving model ...\n","Epoch: 14 \tTraining Loss: 0.923702 \tValidation Loss: 0.985424\n","Epoch: 15 \tTraining Loss: 0.959280 \tValidation Loss: 0.957506\n","Epoch: 16 \tTraining Loss: 0.882372 \tValidation Loss: 0.948324\n","Epoch: 17 \tTraining Loss: 0.907146 \tValidation Loss: 0.926406\n","Validation loss decreased (0.946114 --\u003e 0.926406).  Saving model ...\n","Epoch: 18 \tTraining Loss: 0.924769 \tValidation Loss: 0.958306\n","Epoch: 19 \tTraining Loss: 0.915944 \tValidation Loss: 0.943060\n","Epoch: 20 \tTraining Loss: 0.912861 \tValidation Loss: 0.884162\n","Validation loss decreased (0.926406 --\u003e 0.884162).  Saving model ...\n","Epoch: 21 \tTraining Loss: 0.875101 \tValidation Loss: 0.943493\n","Epoch: 22 \tTraining Loss: 0.879331 \tValidation Loss: 0.902258\n","Epoch: 23 \tTraining Loss: 0.860376 \tValidation Loss: 0.886384\n","Epoch: 24 \tTraining Loss: 0.889335 \tValidation Loss: 0.906272\n","Epoch: 25 \tTraining Loss: 0.853297 \tValidation Loss: 0.962111\n","Epoch: 26 \tTraining Loss: 0.896306 \tValidation Loss: 0.855157\n","Validation loss decreased (0.884162 --\u003e 0.855157).  Saving model ...\n","Epoch: 27 \tTraining Loss: 0.835651 \tValidation Loss: 0.894232\n","Epoch: 28 \tTraining Loss: 0.849094 \tValidation Loss: 0.861912\n","Epoch: 29 \tTraining Loss: 0.844443 \tValidation Loss: 0.841865\n","Validation loss decreased (0.855157 --\u003e 0.841865).  Saving model ...\n","Epoch: 30 \tTraining Loss: 0.834135 \tValidation Loss: 0.861534\n","Epoch: 31 \tTraining Loss: 0.812012 \tValidation Loss: 0.879906\n","Epoch: 32 \tTraining Loss: 0.825542 \tValidation Loss: 0.843911\n","Epoch: 33 \tTraining Loss: 0.784933 \tValidation Loss: 0.869662\n","Epoch: 34 \tTraining Loss: 0.778410 \tValidation Loss: 0.806128\n","Validation loss decreased (0.841865 --\u003e 0.806128).  Saving model ...\n","Epoch: 35 \tTraining Loss: 0.808770 \tValidation Loss: 0.812083\n","Epoch: 36 \tTraining Loss: 0.777218 \tValidation Loss: 0.793021\n","Validation loss decreased (0.806128 --\u003e 0.793021).  Saving model ...\n","Epoch: 37 \tTraining Loss: 0.734858 \tValidation Loss: 0.737474\n","Validation loss decreased (0.793021 --\u003e 0.737474).  Saving model ...\n","Epoch: 38 \tTraining Loss: 0.729628 \tValidation Loss: 0.739941\n","Epoch: 39 \tTraining Loss: 0.772064 \tValidation Loss: 0.762052\n","Epoch: 40 \tTraining Loss: 0.719361 \tValidation Loss: 0.762861\n","Epoch: 41 \tTraining Loss: 0.734085 \tValidation Loss: 0.799478\n","Epoch: 42 \tTraining Loss: 0.820092 \tValidation Loss: 0.853654\n","Epoch: 43 \tTraining Loss: 0.765413 \tValidation Loss: 0.715815\n","Validation loss decreased (0.737474 --\u003e 0.715815).  Saving model ...\n","Epoch: 44 \tTraining Loss: 0.685321 \tValidation Loss: 0.739433\n","Epoch: 45 \tTraining Loss: 0.717441 \tValidation Loss: 0.736306\n","Epoch: 46 \tTraining Loss: 0.694701 \tValidation Loss: 0.683867\n","Validation loss decreased (0.715815 --\u003e 0.683867).  Saving model ...\n","Epoch: 47 \tTraining Loss: 0.716066 \tValidation Loss: 0.779426\n","Epoch: 48 \tTraining Loss: 0.705909 \tValidation Loss: 0.719943\n","Epoch: 49 \tTraining Loss: 0.692132 \tValidation Loss: 0.770787\n","Epoch: 50 \tTraining Loss: 0.703621 \tValidation Loss: 0.707494\n","Epoch: 51 \tTraining Loss: 0.697180 \tValidation Loss: 0.794441\n","Epoch: 52 \tTraining Loss: 0.712228 \tValidation Loss: 0.718405\n","Epoch: 53 \tTraining Loss: 0.728889 \tValidation Loss: 0.684730\n","Epoch: 54 \tTraining Loss: 0.687400 \tValidation Loss: 0.716890\n","Epoch: 55 \tTraining Loss: 0.729110 \tValidation Loss: 0.707355\n","Epoch: 56 \tTraining Loss: 0.730581 \tValidation Loss: 0.701333\n","Epoch: 57 \tTraining Loss: 0.682845 \tValidation Loss: 0.729772\n","Epoch: 58 \tTraining Loss: 0.705432 \tValidation Loss: 0.735506\n","Epoch: 59 \tTraining Loss: 0.689340 \tValidation Loss: 0.687586\n","Epoch: 60 \tTraining Loss: 0.735281 \tValidation Loss: 0.767012\n","Epoch: 61 \tTraining Loss: 0.707351 \tValidation Loss: 0.668440\n","Validation loss decreased (0.683867 --\u003e 0.668440).  Saving model ...\n","Epoch: 62 \tTraining Loss: 0.677140 \tValidation Loss: 0.731079\n","Epoch: 63 \tTraining Loss: 0.665567 \tValidation Loss: 0.719934\n","Epoch: 64 \tTraining Loss: 0.677318 \tValidation Loss: 0.700226\n","Epoch: 65 \tTraining Loss: 0.668777 \tValidation Loss: 0.700976\n","Epoch: 66 \tTraining Loss: 0.678474 \tValidation Loss: 0.663955\n","Validation loss decreased (0.668440 --\u003e 0.663955).  Saving model ...\n","Epoch: 67 \tTraining Loss: 0.668011 \tValidation Loss: 0.713065\n","Epoch: 68 \tTraining Loss: 0.691709 \tValidation Loss: 0.693845\n","Epoch: 69 \tTraining Loss: 0.661440 \tValidation Loss: 0.660319\n","Validation loss decreased (0.663955 --\u003e 0.660319).  Saving model ...\n","Epoch: 70 \tTraining Loss: 0.681337 \tValidation Loss: 0.704193\n","Epoch: 71 \tTraining Loss: 0.668676 \tValidation Loss: 0.673885\n","Epoch: 72 \tTraining Loss: 0.674468 \tValidation Loss: 0.723105\n","Epoch: 73 \tTraining Loss: 0.693209 \tValidation Loss: 0.676595\n","Epoch: 74 \tTraining Loss: 0.707410 \tValidation Loss: 0.702747\n","Epoch: 75 \tTraining Loss: 0.695231 \tValidation Loss: 0.695584\n","Epoch: 76 \tTraining Loss: 0.699327 \tValidation Loss: 0.713147\n","Epoch: 77 \tTraining Loss: 0.787405 \tValidation Loss: 0.865214\n","Epoch: 78 \tTraining Loss: 0.771995 \tValidation Loss: 0.748539\n","Epoch: 79 \tTraining Loss: 0.696124 \tValidation Loss: 0.739795\n","Epoch: 80 \tTraining Loss: 0.776035 \tValidation Loss: 0.779333\n","Epoch: 81 \tTraining Loss: 0.687781 \tValidation Loss: 0.752255\n","Epoch: 82 \tTraining Loss: 0.675883 \tValidation Loss: 0.711794\n","Epoch: 83 \tTraining Loss: 0.706357 \tValidation Loss: 0.711673\n","Epoch: 84 \tTraining Loss: 0.719128 \tValidation Loss: 0.792683\n","Epoch: 85 \tTraining Loss: 1.014146 \tValidation Loss: 0.858818\n","Epoch: 86 \tTraining Loss: 0.789709 \tValidation Loss: 0.724432\n","Epoch: 87 \tTraining Loss: 0.717622 \tValidation Loss: 0.738747\n","Epoch: 88 \tTraining Loss: 0.705743 \tValidation Loss: 0.689645\n","Epoch: 89 \tTraining Loss: 0.689704 \tValidation Loss: 0.680866\n","Epoch: 90 \tTraining Loss: 0.677207 \tValidation Loss: 0.715699\n","Epoch: 91 \tTraining Loss: 0.707508 \tValidation Loss: 0.681620\n","Epoch: 92 \tTraining Loss: 0.706002 \tValidation Loss: 0.729948\n","Epoch: 93 \tTraining Loss: 0.702365 \tValidation Loss: 0.892433\n","Epoch: 94 \tTraining Loss: 0.729389 \tValidation Loss: 0.691766\n","Epoch: 95 \tTraining Loss: 0.739971 \tValidation Loss: 0.672497\n","Epoch: 96 \tTraining Loss: 0.762105 \tValidation Loss: 0.742586\n","Epoch: 97 \tTraining Loss: 0.669918 \tValidation Loss: 0.726996\n","Epoch: 98 \tTraining Loss: 0.706182 \tValidation Loss: 0.677134\n","Epoch: 99 \tTraining Loss: 0.694946 \tValidation Loss: 0.681628\n","Epoch: 100 \tTraining Loss: 0.688559 \tValidation Loss: 0.744307\n"]}],"source":["# number of epochs to train the model\n","n_epochs = 100\n","\n","valid_loss_min = np.Inf # track change in validation loss\n","train_losses, valid_losses = [], []\n","for epoch in range(1, n_epochs+1):\n","\n","    # keep track of training and validation loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    \n","    ###################\n","    # train the model #\n","    ###################\n","    model.train()\n","    for data, target in train_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        #print(output.shape)\n","        #pass\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update training loss\n","        train_loss += loss.item()*data.size(0)\n","        \n","    ######################    \n","    # validate the model #\n","    ######################\n","    model.eval()\n","    for data, target in valid_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        #print(output.shape)\n","        #pass\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # update average validation loss \n","        valid_loss += loss.item()*data.size(0)\n","    \n","    # calculate average losses\n","    train_loss = train_loss/len(train_loader.sampler)\n","    valid_loss = valid_loss/len(valid_loader.sampler)\n","\n","    # At completion of epoch\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","    # print training/validation statistics \n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        epoch, train_loss, valid_loss))\n","    \n","    # save model if validation loss has decreased\n","    if valid_loss \u003c= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --\u003e {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","        torch.save(model.state_dict(), 'katunda_fruit_model.pt')\n","        valid_loss_min = valid_loss"]},{"cell_type":"markdown","metadata":{"id":"YsE0pg390gs_"},"source":["### Plotting loss curves"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1655626163450,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"1b_AfFdb0M7i"},"outputs":[],"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1655626163451,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"bYTGbzcm0Ti0"},"outputs":[],"source":["plt.plot(train_losses, label='Training loss')\n","plt.plot(valid_losses, label='Validation loss')\n","plt.legend(frameon=False)"]},{"cell_type":"markdown","metadata":{"id":"c6EdGXRPaXFc"},"source":["###  Load the Model with the Lowest Validation Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1655626163451,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"WwClBf4CYDE2"},"outputs":[],"source":["model.load_state_dict(torch.load('katunda_fruit_model.pt'))"]},{"cell_type":"markdown","metadata":{"id":"WmRIrgUyabZt"},"source":["---\n","## Test the Trained Network\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1655626163452,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"6TPgd_Iuai75"},"outputs":[],"source":["# track test loss\n","test_loss = 0.0\n","class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","model.eval()\n","# iterate over test data\n","for data, target in test_loader:\n","    # move tensors to GPU if CUDA is available\n","    if train_on_gpu:\n","        data, target = data.cuda(), target.cuda()\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = model(data)\n","    # calculate the batch loss\n","    loss = criterion(output, target)\n","    # update test loss \n","    test_loss += loss.item()*data.size(0)\n","    # convert output probabilities to predicted class\n","    _, pred = torch.max(output, 1)    \n","    # compare predictions to true label\n","    correct_tensor = pred.eq(target.data.view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    # calculate test accuracy for each object class\n","    for i in range(batch_size):\n","        label = target.data[i]\n","        class_correct[label] += correct[i].item()\n","        class_total[label] += 1\n","\n","# average test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(3):\n","    if class_total[i] \u003e 0:\n","        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","            classes[i], 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))"]},{"cell_type":"markdown","metadata":{"id":"m3wmvMG1asB2"},"source":["### Visualize Sample Test Results"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1655626163452,"user":{"displayName":"Tony Blair Ochieng","userId":"18248360752652372425"},"user_tz":-180},"id":"s97HAZP3au6W"},"outputs":[],"source":["# obtain one batch of test images\n","dataiter = iter(test_loader)\n","images, labels = dataiter.next()\n","images.numpy()\n","\n","# move model inputs to cuda, if GPU available\n","if train_on_gpu:\n","    images = images.cuda()\n","\n","# get sample outputs\n","output = model(images)\n","# convert output probabilities to predicted class\n","_, preds_tensor = torch.max(output, 1)\n","preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n","\n","# plot the images in the batch, along with predicted and true labels\n","fig = plt.figure(figsize=(25, 25))\n","for idx in np.arange(20):\n","    ax = fig.add_subplot(4, 5, idx+1, xticks=[], yticks=[])\n","    imshow(images[idx] if not train_on_gpu else images[idx].cpu())\n","    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n","                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"katunda_fruits_classification.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}